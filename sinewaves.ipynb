{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from utils import pretty_matplotlib_style\n",
    "from utils.batching import rnn_minibatch_sequencer\n",
    "from utils.batching import dumb_minibatch_sequencer\n",
    "import tensorflow as tf\n",
    "import math\n",
    "from IPython.display import display\n",
    "print(\"Tensorflow version: \" + tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate fake dataset\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "**Assignment #1**: Choose a waveform. Three possible choices on the next line: 0, 1 or 2\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WAVEFORM_SELECT = 0 # select 0, 1 or 2\n",
    "\n",
    "def create_time_series(datalen):\n",
    "    # good waveforms\n",
    "    frequences = [(0.2, 0.15), (0.35, 0.3), (0.6, 0.55)]\n",
    "    freq1, freq2 = frequences[WAVEFORM_SELECT]\n",
    "    noise = [np.random.random()*0.2 for i in range(datalen)]\n",
    "    x1 = np.sin(np.arange(0,datalen) * freq1)  + noise\n",
    "    x2 = np.sin(np.arange(0,datalen) * freq2)  + noise\n",
    "    x = x1 + x2\n",
    "    return x.astype(np.float32)\n",
    "\n",
    "DATA_SEQ_LEN = 1024*128\n",
    "data = create_time_series(DATA_SEQ_LEN)\n",
    "plt.plot(data[:512])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN_CELLSIZE = 64   # size of the RNN cells\n",
    "NLAYERS = 2         # number of stacked RNN cells (needed for tensor shapes but code must be changed manually)\n",
    "SEQLEN = 16          # unrolled sequence length\n",
    "BATCHSIZE = 32      # mini-batch size\n",
    "DROPOUT_PKEEP = 0.7 # probability of neurons not being dropped (should be between 0.5 and 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize training sequences\n",
    "This is what the neural network will see during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function dumb_minibatch_sequencer splits the data into batches of sequences sequentially.\n",
    "for samples, labels, epoch in dumb_minibatch_sequencer(data, BATCHSIZE, SEQLEN, nb_epochs=1):\n",
    "    break\n",
    "print(\"Sample shape: \" + str(samples.shape))\n",
    "print(\"Label shape: \" + str(labels.shape))\n",
    "print(\"Excerpt from first batch:\")\n",
    "subplot = 231\n",
    "for i in range(6):\n",
    "    plt.subplot(subplot)\n",
    "    plt.plot(samples[i])\n",
    "    subplot += 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The model definition\n",
    "When executed, this function instantiates the Tensorflow graph for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_rnn_fn(features, Hin, labels, dropout_pkeep):\n",
    "    X = features\n",
    "    batchsize = tf.shape(features)[0]\n",
    "    seqlen = tf.shape(features)[1]\n",
    "    \n",
    "    #Here\n",
    "    cells = [tf.nn.rnn_cell.GRUCell(RNN_CELLSIZE) for _ in range(NLAYERS)]\n",
    "    # dropout needed between cell layers only: no output dropout on last cell\n",
    "    dcells = [tf.nn.rnn_cell.DropoutWrapper(cell, output_keep_prob = dropout_pkeep) for cell in cells[:-1]]\n",
    "    dcells.append(cells[-1])\n",
    "    cell = tf.nn.rnn_cell.MultiRNNCell(dcells, state_is_tuple=False)\n",
    "    # X[BATCHSIZE, SEQLEN, 1], Hin[BATCHSIZE, CELLSIZE*NLAYERS]\n",
    "    Yn, H = tf.nn.dynamic_rnn(cell, X, dtype=tf.float32, initial_state=Hin)\n",
    "    # Yn[BATCHSIZE, SEQLEN, RNN_CELLSIZE]\n",
    "    Yn = tf.reshape(Yn, [batchsize*seqlen, RNN_CELLSIZE])\n",
    "    Yr = tf.layers.dense(Yn, 1) # Yr [BATCHSIZE*SEQLEN, 1]\n",
    "    Yr = tf.reshape(Yr, [batchsize, seqlen, 1]) # Yr [BATCHSIZE, SEQLEN, 1]\n",
    "    Yout = Yr[:,-1,:] # Last output Yout [BATCHSIZE, 1]\n",
    "    \n",
    "    loss = tf.losses.mean_squared_error(Yr, labels) # labels[BATCHSIZE, SEQLEN, 1]\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=0.01)\n",
    "    train_op = optimizer.minimize(loss)\n",
    "    \n",
    "    return Yout, H, loss, train_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_identity_fn(features, Hin, labels, dropout_pkeep):\n",
    "    # inputs shapes:\n",
    "    # features [BATCHSIZE, SEQLEN, 1]\n",
    "    # labels [BATCHSIZE, SEQLEN, 1]\n",
    "    # Hin [BATCHSIZE, CELLSIZE*NLAYERS]\n",
    "    \n",
    "    # Goals:\n",
    "    # Tranform input \"features\" into output \"Yout\"\n",
    "    # Tranform input \"Hin\" into output \"H\" (these will be input and output states in an RNN)\n",
    "    # Compute a loss between \"Yout\" and \"labels\" and minimize it\n",
    "    \n",
    "    # dummy model that does almost nothing (one trainable variable is needed)\n",
    "    Yr = features * tf.Variable(tf.ones([]))\n",
    "    H = Hin\n",
    "    \n",
    "    # Yr[BATCHSIZE, SEQLEN, 1]\n",
    "    Yout = Yr[:,-1,:]\n",
    "    # Last output in sequence Yout [BATCHSIZE, 1]\n",
    "    \n",
    "    # shapes:\n",
    "    # Yr [BATCHSIZE, SEQLEN, 1]\n",
    "    # labels[BATCHSIZE, SEQLEN, 1]\n",
    "    loss = tf.losses.mean_squared_error(Yr, labels)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=0.01)\n",
    "    train_op = optimizer.minimize(loss)\n",
    "    \n",
    "    # output shapes:\n",
    "    # Yout [BATCHSIZE, 1]\n",
    "    # H [BATCHSIZE, CELLSIZE*NLAYERS]\n",
    "    return Yout, H, loss, train_op"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# placeholder for inputs\n",
    "Hin = tf.placeholder(tf.float32, [None, RNN_CELLSIZE * NLAYERS])\n",
    "samples = tf.placeholder(tf.float32, [None, None, 1]) # [BATCHSIZE, SEQLEN, 1]\n",
    "labels = tf.placeholder(tf.float32, [None, None, 1]) # [BATCHSIZE, SEQLEN, 1]\n",
    "dropout_pkeep = tf.placeholder(tf.float32)\n",
    "\n",
    "# instantiate the model\n",
    "Yout, H, loss, train_op = model_rnn_fn(samples, Hin, labels, dropout_pkeep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_run(prime_data, run_length):\n",
    "    H_ = np.zeros([1, RNN_CELLSIZE * NLAYERS])\n",
    "    Yout_ = np.zeros([1, 1])\n",
    "    data_len = prime_data.shape[0]\n",
    "\n",
    "    # prime the state from data\n",
    "    if data_len > 0:\n",
    "        Yin = np.array(prime_data)\n",
    "        Yin = np.reshape(Yin, [1, data_len, 1]) # reshape as one sequence\n",
    "        feed = {Hin: H_, samples: Yin, dropout_pkeep: 1.0} # no dropout during inference\n",
    "        Yout_, H_ = sess.run([Yout, H], feed_dict=feed)\n",
    "    \n",
    "    # run prediction\n",
    "    results = []\n",
    "    for i in range(run_length):\n",
    "        Yout_ = np.reshape(Yout_, [1, 1, 1]) # batch of a single sequence of a single vector with one element\n",
    "        feed = {Hin: H_, samples: Yout_, dropout_pkeep: 1.0} # no dropout during inference\n",
    "        Yout_, H_ = sess.run([Yout, H], feed_dict=feed)\n",
    "        results.append(Yout_[0,0])\n",
    "        \n",
    "    return np.array(results), H_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_RMSE(data):\n",
    "    NUMRUNS=50\n",
    "    PRIMELEN=256\n",
    "    RUNLEN=64\n",
    "    sum = 0\n",
    "    datalen = data.shape[0]\n",
    "    for i in range(NUMRUNS):\n",
    "        offset = math.floor(np.random.random() * (datalen - PRIMELEN - RUNLEN))\n",
    "        results, _ = prediction_run(data[offset:offset+PRIMELEN], RUNLEN)\n",
    "        test_data = data[offset+PRIMELEN:offset+PRIMELEN+RUNLEN]\n",
    "        sum += np.mean((results - test_data)**2)\n",
    "    return math.sqrt(sum/NUMRUNS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Tensorflow session\n",
    "This resets all neuron weights and biases to initial random values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first input state\n",
    "Hzero = np.zeros([BATCHSIZE, RNN_CELLSIZE * NLAYERS])\n",
    "# variable initialization\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run([init])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The training loop\n",
    "Re-execute this cell to keep training\n",
    "\n",
    "On waveform 1:\n",
    "1. NB_EPOCHS=5, SEQLEN=8, no dropout, NLAYERS=1, BasicRNNCell, dumb_minibatch_sequencer, no state passing during training:<br>Not very good, some oscillation.\n",
    "1. NB_EPOCHS=5, SEQLEN=16, no dropout, NLAYERS=1, BasicRNNCell, dumb_minibatch_sequencer, no state passing during training:<br>Not very good, some oscillation.\n",
    "1. NB_EPOCHS=5, SEQLEN=32, no dropout, NLAYERS=1, BasicRNNCell, dumb_minibatch_sequencer, no state passing during training:<br>Not very good, some oscillation.\n",
    "1. NB_EPOCHS=5, SEQLEN=32, no dropout, NLAYERS=1, GRUCell, dumb_minibatch_sequencer, no state passing during training:<br>Not very good, some oscillation. Bad track.\n",
    "1. NB_EPOCHS=5, SEQLEN=32, no dropout, NLAYERS=1, BasicRNNCell, dumb_minibatch_sequencer, YES: state passing during training:<br>Not very good, single frequency oscillation.\n",
    "1. NB_EPOCHS=5, SEQLEN=32, no dropout, NLAYERS=1, BasicRNNCell, rnn_minibatch_sequencer, YES: state passing during training:<br>Not very good, single frequency oscillation.\n",
    "1. NB_EPOCHS=5, SEQLEN=32, no dropout, NLAYERS=1, GRUCell, rnn_minibatch_sequencer, YES: state passing during training:<br>Very good!\n",
    "\n",
    "On waveform 0:\n",
    "1. NB_EPOCHS=5, SEQLEN=32, no dropout, NLAYERS=1, GRUCell, rnn_minibatch_sequencer, YES: state passing during training:<br>Not good!\n",
    "1. NB_EPOCHS=10, SEQLEN=32, no dropout, NLAYERS=1, GRUCell, rnn_minibatch_sequencer, YES: state passing during training:<br>Quite good!\n",
    "1. NB_EPOCHS=10, SEQLEN=32, dropout, NLAYERS=2, GRUCell, rnn_minibatch_sequencer, YES: state passing during training:<br>Can still be broken! Running to 20 epochs kind of fixes it.\n",
    "\n",
    "There does not seem to be a big difference between SEQLEN 16 and 32...\n",
    "\n",
    "On waveform 2:\n",
    "1. NB_EPOCHS=5, SEQLEN=32, no dropout, NLAYERS=1, GRUCell, rnn_minibatch_sequencer, YES: state passing during training:<br>Not so good!\n",
    "1. NB_EPOCHS=10, SEQLEN=32, no dropout, NLAYERS=1, GRUCell, rnn_minibatch_sequencer, YES: state passing during training:<br>Quite good! But not always.\n",
    "1. NB_EPOCHS=15, SEQLEN=32, no dropout, NLAYERS=1, GRUCell, rnn_minibatch_sequencer, YES: state passing during training:<br>Very good!\n",
    "\n",
    "The same with dumb_minibatch_sequence do not work.\n",
    "\n",
    "1. NB_EPOCHS=10, SEQLEN=32, dropout=0.7, NLAYERS=2, GRUCell, rnn_minibatch_sequencer, YES: state passing during training:<br>Very good! Always!\n",
    "1. NB_EPOCHS=5, SEQLEN=32, dropout=0.7, NLAYERS=2, GRUCell, rnn_minibatch_sequencer, YES: state passing during training:<br>Quite good! Always! But 10 epochs is better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_EPOCHS = 5\n",
    "\n",
    "H_ = Hzero\n",
    "losses = []\n",
    "indices = []\n",
    "# HERE\n",
    "for i, (next_samples, next_labels, epoch) in enumerate(rnn_minibatch_sequencer(data, BATCHSIZE, SEQLEN, nb_epochs=NB_EPOCHS)):\n",
    "    next_samples = np.expand_dims(next_samples, axis=2)\n",
    "    next_labels = np.expand_dims(next_labels, axis=2)\n",
    "    # HERE\n",
    "    feed = {Hin: H_, samples: next_samples, labels: next_labels, dropout_pkeep: DROPOUT_PKEEP}\n",
    "    Yout_, H_, loss_, train_op_ = sess.run([Yout, H, loss, train_op], feed_dict=feed)\n",
    "    # print progress\n",
    "    if i%100 == 0:\n",
    "        print(\"epoch \" + str(epoch) + \", batch \" + str(i) + \", loss=\" + str(np.mean(loss_)))\n",
    "    if i%10 == 0:\n",
    "        losses.append(np.mean(loss_))\n",
    "        indices.append(i)\n",
    "        \n",
    "# final accuracy (RMSE = Root Mean Squared Error)\n",
    "r = compute_RMSE(data)\n",
    "print(\"final RMSE:\" + str(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.ylim(ymax=np.amax(losses[1:])) # ignore first value for scaling\n",
    "plt.plot(indices, losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRIMELEN=512\n",
    "RUNLEN=512\n",
    "OFFSET=40\n",
    "\n",
    "prime_data = data[OFFSET:OFFSET+PRIMELEN]\n",
    "\n",
    "results, _ = prediction_run(prime_data, RUNLEN)\n",
    "\n",
    "disp_data = data[OFFSET:OFFSET+PRIMELEN+RUNLEN]\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "plt.subplot(211)\n",
    "plt.text(430,2.5,\"DATA\", color=colors[1])\n",
    "plt.text(540,2.5,\"PREDICTED\", color=colors[0])\n",
    "plt.plot(np.concatenate((np.zeros([PRIMELEN]), results)))\n",
    "plt.plot(np.concatenate((prime_data, np.zeros([RUNLEN]))))\n",
    "plt.subplot(212)\n",
    "plt.text(430,2.5,\"DATA\", color=colors[1])\n",
    "plt.text(540,2.5,\"+PREDICTED\", color=colors[0])\n",
    "plt.plot(np.concatenate((np.zeros([PRIMELEN]), results)))\n",
    "plt.plot(disp_data)\n",
    "RMSELEN=64\n",
    "plt.axvspan(PRIMELEN, PRIMELEN+RMSELEN, color='grey', alpha=0.1)\n",
    "plt.show()\n",
    "\n",
    "rmse = math.sqrt(np.mean((data[OFFSET+PRIMELEN:OFFSET+PRIMELEN+RMSELEN] - results[:RMSELEN])**2))\n",
    "print(\"RMSE on {} predictions (shaded area): {}\".format(RMSELEN, rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
