{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An RNN model to generate sequences\n",
    "Generational RNN models can be used to predict stock markets, temperatures, traffic or sales data based on past patterns. They can also be adapted to [generate text](https://docs.google.com/presentation/d/18MiZndRCOxB7g-TcCl2EZOElS5udVaCuxnGznLnmOlE/pub?slide=id.g139650d17f_0_1185). The quality of the prediction will depend on training data, network architecture, hyperparameters, the distance in time at which you are predicting and so on. But most importantly, it will depend on wether your training data contains examples of the behaviour patterns you are trying to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from utils import pretty_matplotlib_style\n",
    "from utils.batching import rnn_minibatch_sequencer\n",
    "from utils.batching import dumb_minibatch_sequencer\n",
    "import tensorflow as tf\n",
    "import math\n",
    "from IPython.display import display\n",
    "print(\"Tensorflow version: \" + tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate fake dataset\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "**Assignment #1**: Choose a waveform. Three possible choices on the next line: 0, 1 or 2\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WAVEFORM_SELECT = 0 # select 0, 1 or 2\n",
    "\n",
    "def create_time_series(datalen):\n",
    "    # good waveforms\n",
    "    frequencies = [(0.2, 0.15), (0.35, 0.3), (0.6, 0.55)]\n",
    "    freq1, freq2 = frequencies[WAVEFORM_SELECT]\n",
    "    noise = [np.random.random()*0.2 for i in range(datalen)]\n",
    "    x1 = np.sin(np.arange(0,datalen) * freq1)  + noise\n",
    "    x2 = np.sin(np.arange(0,datalen) * freq2)  + noise\n",
    "    x = x1 + x2\n",
    "    return x.astype(np.float32)\n",
    "\n",
    "DATA_SEQ_LEN = 1024*128\n",
    "data = create_time_series(DATA_SEQ_LEN)\n",
    "plt.plot(data[:512])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN_CELLSIZE = 64   # size of the RNN cells\n",
    "NLAYERS = 2         # number of stacked RNN cells (needed for tensor shapes but code must be changed manually)\n",
    "SEQLEN = 16         # unrolled sequence length\n",
    "BATCHSIZE = 32      # mini-batch size\n",
    "DROPOUT_PKEEP = 0.7 # probability of neurons not being dropped (should be between 0.5 and 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize training sequences\n",
    "This is what the neural network will see during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function dumb_minibatch_sequencer splits the data into batches of sequences sequentially.\n",
    "for samples, labels, epoch in dumb_minibatch_sequencer(data, BATCHSIZE, SEQLEN, nb_epochs=1):\n",
    "    break\n",
    "print(\"Sample shape: \" + str(samples.shape))\n",
    "print(\"Label shape: \" + str(labels.shape))\n",
    "print(\"Excerpt from first batch:\")\n",
    "subplot = 231\n",
    "for i in range(6):\n",
    "    plt.subplot(subplot)\n",
    "    plt.plot(samples[i])\n",
    "    subplot += 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The model definition\n",
    "When executed, this function instantiates the Tensorflow graph for our model.\n",
    "![deep RNN schematic](images/deep_rnn.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_rnn_fn(features, Hin, labels, dropout_pkeep):\n",
    "    X = features\n",
    "    batchsize = tf.shape(X)[0]\n",
    "    seqlen = tf.shape(X)[1]\n",
    "    \n",
    "    cells = [tf.nn.rnn_cell.GRUCell(RNN_CELLSIZE) for _ in range(NLAYERS)]\n",
    "    # dropout useful between cell layers only: no output dropout on last cell\n",
    "    dcells = [tf.nn.rnn_cell.DropoutWrapper(cell, output_keep_prob = dropout_pkeep) for cell in cells[:-1]]\n",
    "    dcells.append(cells[-1])\n",
    "    # a stacked RNN cell still works like an RNN cell\n",
    "    cell = tf.nn.rnn_cell.MultiRNNCell(dcells, state_is_tuple=False)\n",
    "    # X[BATCHSIZE, SEQLEN, 1], Hin[BATCHSIZE, RNN_CELLSIZE*NLAYERS]\n",
    "    # the sequence unrolling happens here\n",
    "    Yn, H = tf.nn.dynamic_rnn(cell, X, initial_state=Hin)\n",
    "    # Yn[BATCHSIZE, SEQLEN, RNN_CELLSIZE]\n",
    "    Yn = tf.reshape(Yn, [batchsize*seqlen, RNN_CELLSIZE])\n",
    "    Yr = tf.layers.dense(Yn, 1) # Yr [BATCHSIZE*SEQLEN, 1]\n",
    "    Yr = tf.reshape(Yr, [batchsize, seqlen, 1]) # Yr [BATCHSIZE, SEQLEN, 1]\n",
    "    Yout = Yr[:,-1,:] # Last output Yout [BATCHSIZE, 1]\n",
    "    \n",
    "    loss = tf.losses.mean_squared_error(Yr, labels) # labels[BATCHSIZE, SEQLEN, 1]\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=0.01)\n",
    "    train_op = optimizer.minimize(loss)\n",
    "    \n",
    "    return Yout, H, loss, train_op"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# placeholder for inputs\n",
    "Hin = tf.placeholder(tf.float32, [None, RNN_CELLSIZE * NLAYERS])\n",
    "samples = tf.placeholder(tf.float32, [None, None, 1]) # [BATCHSIZE, SEQLEN, 1]\n",
    "labels = tf.placeholder(tf.float32, [None, None, 1]) # [BATCHSIZE, SEQLEN, 1]\n",
    "dropout_pkeep = tf.placeholder(tf.float32)\n",
    "\n",
    "# instantiate the model\n",
    "Yout, H, loss, train_op = model_rnn_fn(samples, Hin, labels, dropout_pkeep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n",
    "This is a generative model: run one trained RNN cell in a loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_run(prime_data, run_length):\n",
    "    H_ = np.zeros([1, RNN_CELLSIZE * NLAYERS]) # zero state initially\n",
    "    Yout_ = np.zeros([1, 1])\n",
    "    data_len = prime_data.shape[0]\n",
    "\n",
    "    # prime the state from data\n",
    "    if data_len > 0:\n",
    "        Yin = np.array(prime_data)\n",
    "        Yin = np.reshape(Yin, [1, data_len, 1]) # reshape as one sequence\n",
    "        feed = {Hin: H_, samples: Yin, dropout_pkeep: 1.0} # no dropout during inference\n",
    "        Yout_, H_ = sess.run([Yout, H], feed_dict=feed)\n",
    "    \n",
    "    # run prediction\n",
    "    # To generate a sequence, run a trained cell in a loop passing as input and input state\n",
    "    # respectively the output and output state from the previous iteration.\n",
    "    results = []\n",
    "    for i in range(run_length):\n",
    "        Yout_ = np.reshape(Yout_, [1, 1, 1]) # batch of a single sequence of a single vector with one element\n",
    "        feed = {Hin: H_, samples: Yout_, dropout_pkeep: 1.0} # no dropout during inference\n",
    "        Yout_, H_ = sess.run([Yout, H], feed_dict=feed)\n",
    "        results.append(Yout_[0,0])\n",
    "        \n",
    "    return np.array(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: kill this, no need for RMSE in this lab\n",
    "#def compute_RMSE(data):\n",
    "#    # Computes RMSE (Root Mean Square Error) on RUNLEN generated values\n",
    "#    # after primimg the state of the RNN with PRIMELEN values.\n",
    "#    # The RMSE is averaged across NUMRUN runs starting from a random point in the dataset.\n",
    "#    NUMRUNS=50\n",
    "#    PRIMELEN=256\n",
    "#    RUNLEN=64\n",
    "#    sum = 0\n",
    "#    datalen = data.shape[0]\n",
    "#    for i in range(NUMRUNS):\n",
    "#        offset = math.floor(np.random.random() * (datalen - PRIMELEN - RUNLEN))\n",
    "#        results = prediction_run(data[offset:offset+PRIMELEN], RUNLEN)\n",
    "#        test_data = data[offset+PRIMELEN:offset+PRIMELEN+RUNLEN]\n",
    "#        sum += np.mean((results - test_data)**2)\n",
    "#    return math.sqrt(sum/NUMRUNS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Tensorflow session\n",
    "This resets all neuron weights and biases to initial random values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first input state\n",
    "Hzero = np.zeros([BATCHSIZE, RNN_CELLSIZE * NLAYERS])\n",
    "# variable initialization\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run([init])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The training loop\n",
    "You can re-execute this cell to continue training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_EPOCHS = 10\n",
    "\n",
    "H_ = Hzero\n",
    "losses = []\n",
    "indices = []\n",
    "for i, (next_samples, next_labels, epoch) in enumerate(rnn_minibatch_sequencer(data, BATCHSIZE, SEQLEN, nb_epochs=NB_EPOCHS)):\n",
    "    next_samples = np.expand_dims(next_samples, axis=2) # model wants 3D inputs [BATCHSIZE, SEQLEN, 1] \n",
    "    next_labels = np.expand_dims(next_labels, axis=2)\n",
    "\n",
    "    feed = {Hin: H_, samples: next_samples, labels: next_labels, dropout_pkeep: DROPOUT_PKEEP}\n",
    "    Yout_, H_, loss_, train_op_ = sess.run([Yout, H, loss, train_op], feed_dict=feed)\n",
    "    # print progress\n",
    "    if i%100 == 0:\n",
    "        print(\"epoch \" + str(epoch) + \", batch \" + str(i) + \", loss=\" + str(np.mean(loss_)))\n",
    "    if i%10 == 0:\n",
    "        losses.append(np.mean(loss_))\n",
    "        indices.append(i)\n",
    "        \n",
    "# TODO: kill this\n",
    "# final accuracy (RMSE = Root Mean Squared Error)\n",
    "#r = compute_RMSE(data)\n",
    "#print(\"final RMSE:\" + str(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.ylim(ymax=np.amax(losses[1:])) # ignore first value for scaling\n",
    "plt.plot(indices, losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRIMELEN=256\n",
    "RUNLEN=512\n",
    "OFFSET=20\n",
    "\n",
    "prime_data = data[OFFSET:OFFSET+PRIMELEN]\n",
    "\n",
    "results = prediction_run(prime_data, RUNLEN)\n",
    "\n",
    "disp_data = data[OFFSET:OFFSET+PRIMELEN+RUNLEN]\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "plt.subplot(211)\n",
    "plt.text(PRIMELEN,2.5,\"DATA |\", color=colors[1], horizontalalignment=\"right\")\n",
    "plt.text(PRIMELEN,2.5,\"| PREDICTED\", color=colors[0], horizontalalignment=\"left\")\n",
    "displayresults = np.ma.array(np.concatenate((np.zeros([PRIMELEN]), results)))\n",
    "displayresults = np.ma.masked_where(displayresults == 0, displayresults)\n",
    "plt.plot(displayresults)\n",
    "displaydata = np.ma.array(np.concatenate((prime_data, np.zeros([RUNLEN]))))\n",
    "displaydata = np.ma.masked_where(displaydata == 0, displaydata)\n",
    "plt.plot(displaydata)\n",
    "plt.subplot(212)\n",
    "plt.text(PRIMELEN,2.5,\"DATA |\", color=colors[1], horizontalalignment=\"right\")\n",
    "plt.text(PRIMELEN,2.5,\"| +PREDICTED\", color=colors[0], horizontalalignment=\"left\")\n",
    "plt.plot(displayresults)\n",
    "plt.plot(disp_data)\n",
    "RMSELEN=128\n",
    "plt.axvspan(PRIMELEN, PRIMELEN+RMSELEN, color='grey', alpha=0.1, ymin=0.05, ymax=0.95)\n",
    "plt.show()\n",
    "\n",
    "rmse = math.sqrt(np.mean((data[OFFSET+PRIMELEN:OFFSET+PRIMELEN+RMSELEN] - results[:RMSELEN])**2))\n",
    "print(\"RMSE on {} predictions (shaded area): {}\".format(RMSELEN, rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
